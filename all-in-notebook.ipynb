{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mszczesniak02/bachlor_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!cp -r /content/bachlor_google/DeepCrack/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A                              # for augmentation transform\n",
    "\n",
    "import numpy as np                                      # sci kit specials ;D\n",
    "import matplotlib.pyplot as plt                         # plots \n",
    "from PIL import Image                                   # for opening images as numpy arrays or torch tensors\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset                    # preset class for creating a dataset\n",
    "from torch.utils.data import random_split               # for splitting datasets into training, test, validation\n",
    "from torch.utils.data import DataLoader                 # self-explanitory\n",
    "import segmentation_models_pytorch as smp               # preset model \n",
    "\n",
    "from tqdm import tqdm                                   # for the progress bar\n",
    "import os                                               # for accessing files and setting proper paths to   them \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter       # tensorboard srv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_PATH = \"../assets/datasets/DeepCrack/train_lab\"\n",
    "IMAGE_PATH = \"../assets/datasets/DeepCrack/train_img\"\n",
    "DEVICE = \"cpu\"\n",
    "WORKERS = 4\n",
    "BATCH_SIZE = 8\n",
    "PIN_MEMORY = True\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(path) -> list:\n",
    "  \"\"\"Return files as their paths+filename in an array\"\"\"\n",
    "\n",
    "  assert (os.path.exists(path) == True),  \"Failure during data fetching\"  \n",
    "      \n",
    "  result = []\n",
    "  for file in tqdm(os.listdir(path), desc=f\"Loading files from {path} \",unit=\"File\", leave=True):\n",
    "    fpath = os.path.join(path,file)\n",
    "    result.append(fpath)\n",
    "  \n",
    "  return result\n",
    "\n",
    "\n",
    "class DeepCrackDataset(Dataset):\n",
    "  def __init__(self, img_dir, mask_dir, transform=None):\n",
    "    \n",
    "    self.img_dir = img_dir\n",
    "    self.mask_dir = mask_dir\n",
    "    self.transform = transform\n",
    "\n",
    "    # sort values so the file names corespoding to each other are loaded in order\n",
    "    self.images = sorted([os.path.join(img_dir, file) for file in os.listdir(img_dir)] )\n",
    "    self.masks = sorted([os.path.join(mask_dir, file) for file in os.listdir(mask_dir)]) \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    np_image = np.array(Image.open(self.images[index]))\n",
    "    np_mask = np.array(Image.open(self.masks[index])) \n",
    "\n",
    "   \n",
    "    if len(np_mask.shape) == 3:\n",
    "      np_mask = np_mask[:,:,0]\n",
    "\n",
    "    np_mask = (np_mask > 127).astype(np.uint8)\n",
    "    \n",
    "    if self.transform: # if using transforms\n",
    "      t = self.transform(image=np_image, mask=np_mask)\n",
    "      np_image = t[\"image\"]\n",
    "      np_mask = t[\"mask\"]\n",
    "\n",
    "    # conversion from numpy array convention to tensor via permute, \n",
    "    #     then normalizing to [0,1] range, same for mask, only using binary data\n",
    "    tensor_image = torch.from_numpy(np_image).permute(2, 0, 1).float() / 255.0\n",
    "    tensor_mask = torch.from_numpy(np_mask).unsqueeze(0).float() \n",
    "\n",
    "    return tensor_image,tensor_mask\n",
    "\n",
    "\n",
    "def get_dataset(img_path = IMAGE_PATH, mask_path = MASK_PATH ):\n",
    "  \n",
    "  dataset = DeepCrackDataset(img_path, mask_path, transform=transofrm_train)\n",
    "  return dataset\n",
    "\n",
    "def split_dataset(dataset: DeepCrackDataset, train_factor, test_factor, val_factor )->list:\n",
    "  \"\"\"Split exising dataset given percentages as [0,1] floats, return list of  \"\"\"\n",
    "  train_set_len, test_set_len, val_set_len = int(dataset.__len__() * train_factor), int(dataset.__len__() * test_factor) , int(dataset.__len__() * val_factor)\n",
    "  train_set, test_set ,val_set = random_split(dataset, [train_set_len, test_set_len, val_set_len])\n",
    "  \n",
    "  return [train_set, test_set, val_set]\n",
    "\n",
    "def show_dataset(data_loader, samples=4):\n",
    "    counter = 0\n",
    "    for images, masks in data_loader:        \n",
    "        fig, axes = plt.subplots(samples, 2, figsize=(8, 12))\n",
    "        for i in range( samples ):\n",
    "            \n",
    "            img = images[i].permute(1, 2, 0).numpy()\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            # # Maska\n",
    "            mask = masks[i, 0].numpy()\n",
    "            axes[i, 1].imshow(mask, cmap='gray')\n",
    "            axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "            axes[i, 1].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transofrm_train = A.Compose([\n",
    "    A.RandomResizedCrop(size=(256,256),scale=(0.5, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),  \n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "], seed=np.random.randint(low=1, high=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "  def __init__(self, smooth=1e-6):\n",
    "    super(DiceLoss,self).__init__()\n",
    "    self.smooth = smooth\n",
    "  def forward(self, predictions, targets):\n",
    "    predictions = torch.sigmoid(predictions)\n",
    "\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    intersection = (predictions * targets).sum()\n",
    "    dice = (2. * intersection  + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "    return 1-dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = .0\n",
    "\n",
    "    for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        # move to adequete memory \n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(images)\n",
    "        loss = criterion(predictions, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "def validate(model, val_loader, criterion,device):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images,masks in val_loader:\n",
    "      images = images.to(device)\n",
    "      masks = masks.to(device)\n",
    "\n",
    "      predictions = model(images)\n",
    "      loss = criterion(predictions, masks)\n",
    "\n",
    "      running_loss += loss.item()\n",
    "  \n",
    "  avg_loss = running_loss / len(val_loader)\n",
    "  return avg_loss\n",
    "\n",
    "\n",
    "def make_checkpoint(model, optimizer, best_val_loss, training_loss):\n",
    "   torch.save({\n",
    "      'epoch': EPOCHS,\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'train_loss': training_loss,\n",
    "      'val_loss': best_val_loss,} , 'unet_MODEL_save.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Kompletna ewaluacja modelu\n",
    "    \n",
    "    Returns:\n",
    "        metrics: dict z metrykami\n",
    "        predictions: array predykcji [N, H, W]\n",
    "        ground_truths: array prawdziwych masek [N, H, W]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_ground_truths = []\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Do CPU\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_ground_truths.append(masks.cpu().numpy())\n",
    "    \n",
    "    # Concatenate\n",
    "    predictions = np.concatenate(all_predictions, axis=0)[:, 0]  # [N, H, W]\n",
    "    ground_truths = np.concatenate(all_ground_truths, axis=0)[:, 0]  # [N, H, W]\n",
    "    \n",
    "    # Binaryzacja\n",
    "    pred_binary = (predictions > threshold).astype(np.float32)\n",
    "    gt_binary = (ground_truths > 0.5).astype(np.float32)\n",
    "    \n",
    "    # ========================================\n",
    "    # OBLICZ METRYKI\n",
    "    # ========================================\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for pred, gt in zip(pred_binary, gt_binary):\n",
    "        # Confusion matrix\n",
    "        tp = (pred * gt).sum()\n",
    "        fp = (pred * (1 - gt)).sum()\n",
    "        fn = ((1 - pred) * gt).sum()\n",
    "        tn = ((1 - pred) * (1 - gt)).sum()\n",
    "        \n",
    "        # IoU (Intersection over Union)\n",
    "        iou = tp / (tp + fp + fn + 1e-6)\n",
    "        ious.append(iou)\n",
    "        \n",
    "        # Precision (jakość detekcji)\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        # Recall (czułość)\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        # F1 Score (harmonic mean)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    metrics = {\n",
    "        'iou_mean': np.mean(ious),\n",
    "        'iou_std': np.std(ious),\n",
    "        'iou_median': np.median(ious),\n",
    "        'precision_mean': np.mean(precisions),\n",
    "        'precision_std': np.std(precisions),\n",
    "        'recall_mean': np.mean(recalls),\n",
    "        'recall_std': np.std(recalls),\n",
    "        'f1_mean': np.mean(f1_scores),\n",
    "        'f1_std': np.std(f1_scores),\n",
    "        'accuracy_mean': np.mean(accuracies),\n",
    "        'ious': ious,\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'f1_scores': f1_scores,\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main()-> int:\n",
    "\n",
    "    dataset = get_dataset(IMAGE_PATH, MASK_PATH)\n",
    "    [train_set, test_set, val_set] = split_dataset(dataset, .8, .1, .1)\n",
    "\n",
    "    train_loader = DataLoader( train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=PIN_MEMORY)\n",
    "    test_loader = DataLoader( test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=PIN_MEMORY)\n",
    "    val_loader = DataLoader( val_set, batch_size=BATCH_SIZE , shuffle=False, num_workers=WORKERS    , pin_memory=PIN_MEMORY)\n",
    "\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "    model = model.to(device)       \n",
    "\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(60*'.')\n",
    "    print(f\"\\n Model size:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
    "\n",
    "\n",
    "\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "\n",
    "    print(60*'.')\n",
    "    print(\"\\n Optimizer:\")\n",
    "    print(f\"   Type: Adam\")\n",
    "    print(f\"   Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "    print(f\"   Weight decay: {optimizer.param_groups[0]['weight_decay']}\")\n",
    "    print(60*'.')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    epochs = EPOCHS\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    epochs_time = []\n",
    "\n",
    "    loop = tqdm(range(epochs), unit=\"Epoch\", leave=True)\n",
    "\n",
    "    for epoch in loop:\n",
    "        \n",
    "\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "\n",
    "        epochs_time.append(loop.format_dict['elapsed'])\n",
    "\n",
    "        loop.set_description(f\"Current Loss:{best_val_loss}\" )\n",
    "        loop.update()\n",
    "\n",
    "    loop.close()\n",
    "\n",
    "    print(\"TRAINING COMPLETED!\")\n",
    "    print(f\"Best Val Loss: {best_val_loss:.4f}\")\n",
    "\n",
    "    print(\"\\t Training time per epoch:\")\n",
    "    [print(f\"epoch {i+1} {epochs_time[i] }s\") for i in range(len(epochs_time))]\n",
    "\n",
    "    make_checkpoint(model, optimizer, best_val_loss, train_loss)\n",
    "\n",
    "    metrics, predictions, ground_truths = evaluate_model(model, test_loader, device)\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "else:\n",
    "  pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
