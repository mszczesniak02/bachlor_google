{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/mszczesniak02/bachlor_google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!cp -r /content/bachlor_google/DeepCrack/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "tags": [
     "command"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A                              # for augmentation transform\n",
    "\n",
    "import numpy as np                                      # sci kit specials ;D\n",
    "import matplotlib.pyplot as plt                         # plots \n",
    "from PIL import Image                                   # for opening images as numpy arrays or torch tensors\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset                    # preset class for creating a dataset\n",
    "from torch.utils.data import random_split               # for splitting datasets into training, test, validation\n",
    "from torch.utils.data import DataLoader                 # self-explanitory\n",
    "import segmentation_models_pytorch as smp               # preset model \n",
    "\n",
    "from tqdm import tqdm                                   # for the progress bar\n",
    "import os                                               # for accessing files and setting proper paths to   them \n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter       # tensorboard srv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "\n",
    "if DEBUG==True:\n",
    "   \n",
    "  MASK_PATH = \"../assets/datasets/DeepCrack/train_lab\"\n",
    "  IMAGE_PATH = \"../assets/datasets/DeepCrack/train_img\"\n",
    "  DEVICE = \"cpu\"\n",
    "  WORKERS = 4\n",
    "\n",
    "else:\n",
    "  MASK_PATH = \"/content/DeepCrack/train_lab\"\n",
    "  IMAGE_PATH = \"/content/DeepCrack/train_img\"\n",
    "  DEVICE=\"cuda\"  \n",
    "  WORKERS = 2\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "PIN_MEMORY = True\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EPOCHS = 3\n",
    "\n",
    "EARLY_STOPPING_PATIENCE = 15\n",
    "\n",
    "SCHEDULER_PATIENCE = 5\n",
    "SCHEDULER_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(path) -> list:\n",
    "  \"\"\"Return files as their paths+filename in an array\"\"\"\n",
    "\n",
    "  assert (os.path.exists(path) == True),  \"Failure during data fetching\"  \n",
    "      \n",
    "  result = []\n",
    "  for file in tqdm(os.listdir(path), desc=f\"Loading files from {path} \",unit=\"File\", leave=True):\n",
    "    fpath = os.path.join(path,file)\n",
    "    result.append(fpath)\n",
    "  \n",
    "  return result\n",
    "\n",
    "\n",
    "class DeepCrackDataset(Dataset):\n",
    "  def __init__(self, img_dir, mask_dir, transform=None):\n",
    "    \n",
    "    self.img_dir = img_dir\n",
    "    self.mask_dir = mask_dir\n",
    "    self.transform = transform\n",
    "\n",
    "    # sort values so the file names corespoding to each other are loaded in order\n",
    "    self.images = sorted([os.path.join(img_dir, file) for file in os.listdir(img_dir)] )\n",
    "    self.masks = sorted([os.path.join(mask_dir, file) for file in os.listdir(mask_dir)]) \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    np_image = np.array(Image.open(self.images[index]))\n",
    "    np_mask = np.array(Image.open(self.masks[index])) \n",
    "\n",
    "   \n",
    "    if len(np_mask.shape) == 3:\n",
    "      np_mask = np_mask[:,:,0]\n",
    "\n",
    "    np_mask = (np_mask > 127).astype(np.uint8)\n",
    "    \n",
    "    if self.transform: # if using transforms\n",
    "      t = self.transform(image=np_image, mask=np_mask)\n",
    "      np_image = t[\"image\"]\n",
    "      np_mask = t[\"mask\"]\n",
    "\n",
    "    # conversion from numpy array convention to tensor via permute, \n",
    "    #     then normalizing to [0,1] range, same for mask, only using binary data\n",
    "    tensor_image = torch.from_numpy(np_image).permute(2, 0, 1).float() / 255.0\n",
    "    tensor_mask = torch.from_numpy(np_mask).unsqueeze(0).float() \n",
    "\n",
    "    return tensor_image,tensor_mask\n",
    "\n",
    "\n",
    "def get_dataset(img_path = IMAGE_PATH, mask_path = MASK_PATH ):\n",
    "  \n",
    "  dataset = DeepCrackDataset(img_path, mask_path, transform=transofrm_train)\n",
    "  return dataset\n",
    "\n",
    "def split_dataset(dataset: DeepCrackDataset, train_factor, test_factor, val_factor )->list:\n",
    "  \"\"\"Split exising dataset given percentages as [0,1] floats, return list of  \"\"\"\n",
    "  train_set_len, test_set_len, val_set_len = int(dataset.__len__() * train_factor), int(dataset.__len__() * test_factor) , int(dataset.__len__() * val_factor)\n",
    "  train_set, test_set ,val_set = random_split(dataset, [train_set_len, test_set_len, val_set_len])\n",
    "  \n",
    "  return [train_set, test_set, val_set]\n",
    "\n",
    "def show_dataset(data_loader, samples=4):\n",
    "    counter = 0\n",
    "    for images, masks in data_loader:        \n",
    "        fig, axes = plt.subplots(samples, 2, figsize=(8, 12))\n",
    "        for i in range( samples ):\n",
    "            \n",
    "            img = images[i].permute(1, 2, 0).numpy()\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"Image {i+1}\")\n",
    "            axes[i, 0].axis('off')\n",
    "\n",
    "            # # Maska\n",
    "            mask = masks[i, 0].numpy()\n",
    "            axes[i, 1].imshow(mask, cmap='gray')\n",
    "            axes[i, 1].set_title(f\"Mask {i+1}\")\n",
    "            axes[i, 1].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transofrm_train = A.Compose([\n",
    "    A.RandomResizedCrop(size=(256,256),scale=(0.5, 1.0)),\n",
    "    A.HorizontalFlip(p=0.5),  \n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "], seed=np.random.randint(low=1, high=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "  def __init__(self, smooth=1e-6):\n",
    "    super(DiceLoss,self).__init__()\n",
    "    self.smooth = smooth\n",
    "  def forward(self, predictions, targets):\n",
    "    predictions = torch.sigmoid(predictions)\n",
    "\n",
    "    predictions = predictions.view(-1)\n",
    "    targets = targets.view(-1)\n",
    "\n",
    "    intersection = (predictions * targets).sum()\n",
    "    dice = (2. * intersection  + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "\n",
    "    return 1-dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, targets, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Oblicz metryki segmentacji dla pojedynczego batcha\n",
    "    \n",
    "    Args:\n",
    "        predictions: tensor [B, 1, H, W] - output z modelu (po sigmoid)\n",
    "        targets: tensor [B, 1, H, W] - ground truth maski\n",
    "        threshold: próg binaryzacji (default 0.5)\n",
    "    \n",
    "    Returns:\n",
    "        dict z metrykami\n",
    "    \"\"\"\n",
    "    # Binaryzacja\n",
    "    preds = (predictions > threshold).float()\n",
    "    targets = targets.float()\n",
    "    \n",
    "    # Flatten\n",
    "    preds_flat = preds.view(-1)\n",
    "    targets_flat = targets.view(-1)\n",
    "    \n",
    "    # True/False Positives/Negatives\n",
    "    TP = ((preds_flat == 1) & (targets_flat == 1)).sum().float()\n",
    "    TN = ((preds_flat == 0) & (targets_flat == 0)).sum().float()\n",
    "    FP = ((preds_flat == 1) & (targets_flat == 0)).sum().float()\n",
    "    FN = ((preds_flat == 0) & (targets_flat == 1)).sum().float()\n",
    "    \n",
    "    # Metryki\n",
    "    epsilon = 1e-7  # Unikaj dzielenia przez zero\n",
    "    \n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN + epsilon)\n",
    "    precision = TP / (TP + FP + epsilon)\n",
    "    recall = TP / (TP + FN + epsilon)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + epsilon)\n",
    "    specificity = TN / (TN + FP + epsilon)\n",
    "    \n",
    "    # IoU (Intersection over Union) - NAJWAŻNIEJSZA dla segmentacji!\n",
    "    intersection = (preds * targets).sum()\n",
    "    union = preds.sum() + targets.sum() - intersection\n",
    "    iou = intersection / (union + epsilon)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    dice = (2 * intersection) / (preds.sum() + targets.sum() + epsilon)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1_score': f1_score.item(),\n",
    "        'specificity': specificity.item(),\n",
    "        'iou': iou.item(),\n",
    "        'dice': dice.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = .0\n",
    "    metrics = {\n",
    "        'iou': [], 'dice': [], 'recall': [], \n",
    "        'precision': [], 'f1_score': []\n",
    "    }\n",
    "    loop = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch_idx, (images, masks) in enumerate(loop):\n",
    "        # move to adequete memory \n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(images)\n",
    "        loss = criterion(predictions, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions_sigmoid = torch.sigmoid(predictions)\n",
    "            batch_metrics = calculate_metrics(predictions_sigmoid, masks)\n",
    "            \n",
    "            for key in metrics.keys():\n",
    "                metrics[key].append(batch_metrics[key])\n",
    "        \n",
    "        loop.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    loop.close()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    avg_metrics['loss'] = avg_loss\n",
    "    \n",
    "\n",
    "    return avg_metrics\n",
    "\n",
    "def validate(model, val_loader, criterion,device):\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  metrics = {\n",
    "      'iou': [], 'dice': [], 'recall': [], \n",
    "      'precision': [], 'f1_score': [], 'accuracy': []\n",
    "      }\n",
    "  with torch.no_grad():\n",
    "    for images,masks in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "      images = images.to(device)\n",
    "      masks = masks.to(device)\n",
    "\n",
    "      predictions = model(images)\n",
    "      loss = criterion(predictions, masks)\n",
    "\n",
    "      running_loss += loss.item()\n",
    "\n",
    "      predictions_sigmoid = torch.sigmoid(predictions)\n",
    "      batch_metrics = calculate_metrics(predictions_sigmoid, masks)\n",
    "            \n",
    "      for key in metrics.keys():\n",
    "          metrics[key].append(batch_metrics[key])\n",
    "  \n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "    avg_metrics['loss'] = avg_loss\n",
    "    \n",
    "    return avg_metrics\n",
    "\n",
    "\n",
    "\n",
    "def make_checkpoint(model, optimizer, best_val_loss, training_loss):\n",
    "   torch.save({\n",
    "      'epoch': EPOCHS,\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'train_loss': training_loss,\n",
    "      'val_loss': best_val_loss,} , 'unet_MODEL_save.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Kompletna ewaluacja modelu\n",
    "    \n",
    "    Returns:\n",
    "        metrics: dict z metrykami\n",
    "        predictions: array predykcji [N, H, W]\n",
    "        ground_truths: array prawdziwych masek [N, H, W]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_ground_truths = []\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc=\"Processing batches\"):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            predictions = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Do CPU\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_ground_truths.append(masks.cpu().numpy())\n",
    "    \n",
    "    # Concatenate\n",
    "    predictions = np.concatenate(all_predictions, axis=0)[:, 0]  # [N, H, W]\n",
    "    ground_truths = np.concatenate(all_ground_truths, axis=0)[:, 0]  # [N, H, W]\n",
    "    \n",
    "    # Binaryzacja\n",
    "    pred_binary = (predictions > threshold).astype(np.float32)\n",
    "    gt_binary = (ground_truths > 0.5).astype(np.float32)\n",
    "    \n",
    "    # ========================================\n",
    "    # OBLICZ METRYKI\n",
    "    # ========================================\n",
    "    ious = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for pred, gt in zip(pred_binary, gt_binary):\n",
    "        # Confusion matrix\n",
    "        tp = (pred * gt).sum()\n",
    "        fp = (pred * (1 - gt)).sum()\n",
    "        fn = ((1 - pred) * gt).sum()\n",
    "        tn = ((1 - pred) * (1 - gt)).sum()\n",
    "        \n",
    "        # IoU (Intersection over Union)\n",
    "        iou = tp / (tp + fp + fn + 1e-6)\n",
    "        ious.append(iou)\n",
    "        \n",
    "        # Precision (jakość detekcji)\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precisions.append(precision)\n",
    "        \n",
    "        # Recall (czułość)\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "        # F1 Score (harmonic mean)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn + 1e-6)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    metrics = {\n",
    "        'iou_mean': np.mean(ious),\n",
    "        'iou_std': np.std(ious),\n",
    "        'iou_median': np.median(ious),\n",
    "        'precision_mean': np.mean(precisions),\n",
    "        'precision_std': np.std(precisions),\n",
    "        'recall_mean': np.mean(recalls),\n",
    "        'recall_std': np.std(recalls),\n",
    "        'f1_mean': np.mean(f1_scores),\n",
    "        'f1_std': np.std(f1_scores),\n",
    "        'accuracy_mean': np.mean(accuracies),\n",
    "        'ious': ious,\n",
    "        'precisions': precisions,\n",
    "        'recalls': recalls,\n",
    "        'f1_scores': f1_scores,\n",
    "    }\n",
    "    \n",
    "    return metrics, predictions, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main()-> int:\n",
    "\n",
    "    dataset = get_dataset(IMAGE_PATH, MASK_PATH)\n",
    "    [train_set, test_set, val_set] = split_dataset(dataset, .8, .1, .1)\n",
    "\n",
    "    train_loader = DataLoader( train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKERS, pin_memory=PIN_MEMORY)\n",
    "    test_loader = DataLoader( test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKERS, pin_memory=PIN_MEMORY)\n",
    "    val_loader = DataLoader( val_set, batch_size=BATCH_SIZE , shuffle=False, num_workers=WORKERS    , pin_memory=PIN_MEMORY)\n",
    "\n",
    "    print(\"Loading datasets...\")    \n",
    "    print(f\"   Train: {len(train_set)} images\")\n",
    "    print(f\"   Val:   {len(val_set)} images\")\n",
    "    print(f\"   Test:  {len(test_set)} images\")\n",
    "\n",
    "    device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    )\n",
    "\n",
    "    model = model.to(device)       \n",
    "\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Model size: ~{total_params * 4 / 1e6:.1f} MB\")\n",
    "\n",
    "\n",
    "\n",
    "    criterion = DiceLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "    )\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',  # Maksymalizuj IoU\n",
    "        factor=SCHEDULER_FACTOR,\n",
    "        patience=SCHEDULER_PATIENCE,\n",
    "        verbose=True,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining configuration:\")\n",
    "    print(f\"   Optimizer: Adam\")\n",
    "    print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "    print(f\"   Weight decay: {WEIGHT_DECAY}\")\n",
    "    print(f\"   Scheduler: ReduceLROnPlateau (patience={SCHEDULER_PATIENCE})\")\n",
    "    print(f\"   Early stopping: patience={EARLY_STOPPING_PATIENCE}\")\n",
    "    print(f\"   Epochs: {EPOCHS}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    epochs = EPOCHS\n",
    "    best_val_iou = 0.0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        \n",
    "        # TRAIN\n",
    "        train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # VALIDATE\n",
    "        val_metrics = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        # SCHEDULER\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        scheduler.step(val_metrics['iou'])\n",
    "\n",
    "        \n",
    "\n",
    "       # ========================================\n",
    "        # PRINT METRICS\n",
    "        # ========================================\n",
    "        print(f\"\\nTraining:\")\n",
    "        print(f\"   Loss: {train_metrics['loss']:.4f}\")\n",
    "        print(f\"   IoU:  {train_metrics['iou']:.4f}\")\n",
    "        print(f\"   Dice: {train_metrics['dice']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nValidation:\")\n",
    "        print(f\"   Loss:      {val_metrics['loss']:.4f}\")\n",
    "        print(f\"   IoU:       {val_metrics['iou']:.4f} {'✅ NEW BEST!' if val_metrics['iou'] > best_val_iou else ''}\")\n",
    "        print(f\"   Dice:      {val_metrics['dice']:.4f}\")\n",
    "        print(f\"   Recall:    {val_metrics['recall']:.4f}\")\n",
    "        print(f\"   Precision: {val_metrics['precision']:.4f}\")\n",
    "        print(f\"   F1-Score:  {val_metrics['f1_score']:.4f}\")\n",
    "        \n",
    "        print(f\"\\n LR: {current_lr:.6f}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # SAVE BEST MODEL\n",
    "        # ========================================\n",
    "        if val_metrics['iou'] > best_val_iou:\n",
    "            best_val_iou = val_metrics['iou']\n",
    "            best_epoch = epoch\n",
    "            patience_counter = 0\n",
    "            \n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_iou': best_val_iou,\n",
    "                'val_metrics': val_metrics,\n",
    "                'train_metrics': train_metrics,\n",
    "            }\n",
    "            \n",
    "            torch.save(checkpoint, f'best_model_iou_{best_val_iou:.4f}.pth')\n",
    "            print(f\"\\n Model saved: best_model_iou_{best_val_iou:.4f}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"\\n No improvement for {patience_counter} epoch(s)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # EARLY STOPPING\n",
    "        # ========================================\n",
    "        if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"\\n  Early stopping triggered!\")\n",
    "            print(f\"   No improvement for {EARLY_STOPPING_PATIENCE} epochs\")\n",
    "            print(f\"   Best IoU: {best_val_iou:.4f} at epoch {best_epoch + 1}\")\n",
    "            break\n",
    "    \n",
    "    # ========================================\n",
    "    # FINAL EVALUATION ON TEST SET\n",
    "    # ========================================\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Final evaluation on test set...\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "    \n",
    "    # Load best model\n",
    "    checkpoint = torch.load(f'best_model_iou_{best_val_iou:.4f}.pth')\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    test_metrics = validate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"   IoU:       {test_metrics['iou']:.4f}\")\n",
    "    print(f\"   Dice:      {test_metrics['dice']:.4f}\")\n",
    "    print(f\"   Recall:    {test_metrics['recall']:.4f}\")\n",
    "    print(f\"   Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"   F1-Score:  {test_metrics['f1_score']:.4f}\")\n",
    "    print(f\"   Accuracy:  {test_metrics['accuracy']:.4f}\")\n",
    "    \n",
    "    # Save to TensorBoard\n",
    "    # writer.add_text('Final_Test_Metrics', str(test_metrics))\n",
    "    \n",
    "    # writer.close()\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\" TRAINING COMPLETED!\")\n",
    "    print(f\"   Best Validation IoU: {best_val_iou:.4f} (epoch {best_epoch + 1})\")\n",
    "    print(f\"   Test IoU: {test_metrics['iou']:.4f}\")\n",
    "    print(f\"   Model saved as: best_model_iou_{best_val_iou:.4f}.pth\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()\n",
    "else:\n",
    "  pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
